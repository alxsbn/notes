---
layout: post
title: "Friction in an Agentic World"
date: 2026-01-01
categories: ai productivity philosophy
---

Reintroducing friction isn't a bug. It's a **political choice**.

A costly choice: it slows things down, complicates them. Rarely made — unless you understand that **the cost of friction is lower than the cost of fragility**.

## Preserve non-automated zones

Not out of nostalgia — for **cognitive hygiene**. Spaces where you keep doing things yourself, making mistakes, understanding why things break. The point is that it's a choice of **competence**, not technological lag.

## Organize cognitive fire drills

Regularly unplug the agent and replay by hand. Verify you still know how. It's tedious, it's slow — that's exactly why it's useful.

## Establish a right to incomprehension

Not a right to understand everything — that's impossible. But a **right to demand justification** before approving. "The agent says..." cannot be a sufficient argument.

## Evaluate agents on recoverability, not results

A good tool is one you can unplug. If the agent goes down tomorrow, how long before the collective is operational? If the answer is "several weeks," there's a **design problem**.

## Document the trade-offs, not just the outputs

When you configure an agent, you make choices. Those choices should be traceable, explicit, contestable — not buried in a prompt no one rereads.

---

These measures slow things down. They require unproductive time — that is, **political time**. That's precisely why they won't be taken by default.

Friction isn't an obstacle to efficiency. **It's the price of resilience**.
